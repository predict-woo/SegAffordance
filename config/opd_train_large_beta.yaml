# Default configuration for training CRIS on OPDReal data

# Model Architecture (CRIS defaults, user should verify/override for their specific CRIS variant)
clip_pretrain: "pretrain/RN50.pt" # Assumes a valid CLIP model is at this path
word_len: 77                     # Standard CLIP context length
fpn_in: [512, 1024, 1024]      # Input channels for FPN from backbone.
fpn_out: [256, 512, 1024]        # Output channels for FPN layers.
sync_bn: True                   # Whether to use SyncBatchNorm

# Decoder (Transformer)
num_layers: 3                    # Number of layers in Transformer decoder
num_head: 8                      # Number of attention heads
dim_ffn: 1024                    # Dimension of feed-forward network in Transformer
dropout: 0.2                     # Dropout rate in Transformer
intermediate: False              # Whether the Transformer decoder returns intermediate layer outputs

# VAE for Motion Prediction
vae_latent_dim: 32
vae_hidden_dim: 256

# Depth Encoder
depth_feat_channels: [128, 256]

# Data and Dataloaders for OPDReal
data_path: "/cluster/project/cvg/students/andrye/dataset/MotionDataset_h5_real"
train_dataset_key: "MotionNet_train" # Key for the training dataset split
val_dataset_key: "MotionNet_valid"   # Key for the validation dataset split
input_size: [256, 256]           # Image input size (height, width)
batch_size_train: 64
batch_size_val: 64
num_workers_train: 16
num_workers_val: 16

# Optimizer & Scheduler
optimizer_lr: 0.00001
optimizer_weight_decay: 0.0001
scheduler_milestones: [20, 25]   # Epochs at which to decay learning rate
scheduler_gamma: 0.1             # LR decay factor

# motion type
num_motion_types: 2

# Loss functions
loss_bce_weight: 0.5             # Weight for BCE loss in DiceBCELoss
loss_dice_weight: 0.5            # Weight for Dice loss in DiceBCELoss

# loss weights
loss_coord_weight: 0.5          # Weight for the L1 coordinate regression loss
loss_vae_weight: 0.5
loss_motion_type_weight: 0.5

# loss parameters
loss_point_sigma: 8.0            # Sigma for Gaussian heatmap generation (in pixels on the feature map)
loss_vae_beta: 0.01


# Trainer settings
max_epochs: 30
gpus: 1                          # Number of GPUs to use. If 1, uses GPU 0. If >1, uses specified number of GPUs. If 0, uses CPU.
precision: 32                    # 32 for float32, 16 for mixed-precision
exp_name: "OPDReal_w_motion_type_v6"
output_dir: "/cluster/project/cvg/students/andrye/experiments/OPDReal_w_motion_type_v6" # Base directory for outputs, will be exp_name within this.
manual_seed: 42
enable_wandb: True              # Set to true to enable Weights & Biases logging
wandb_project: "OPD"     # WandB project name
# wandb_entity: "your_wandb_entity" # Optional: WandB entity (username or team) 

wandb_show_loading_bar: True
log_image_interval_steps: 100